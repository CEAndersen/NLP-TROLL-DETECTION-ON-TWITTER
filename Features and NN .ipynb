{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Pia/Desktop/NLP/LDA\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/Pia/Desktop/NLP/LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A                                                  B  WC  Analytic  Clout  \\\n",
      "0   0           #ThingsDoneByMistake kissing auntie lips   4     38.60  99.00   \n",
      "1   8  NickTomaWBRE  Nick  holding  Miners  Trump ral...   9     93.26  50.00   \n",
      "2  18                 mikefdupjourney shenutt  welcome     3     93.26  99.00   \n",
      "3  22   TrumpSuperPAC #AfricanAmericans like JermonMa...  13     97.95  50.00   \n",
      "4  23   AmericanWoman #MAGA#FEMININEAMERICATRUMP#LGBT...  12     93.26  50.00   \n",
      "5  25   HoofHearted TuckerCarlson\\nJRubinBlogger #Big...  12     81.63  79.76   \n",
      "6  31   heal Proof  Mainstream Media  Become  Joke [W...   9     93.26  50.00   \n",
      "7  34   justenoughtrope  turns  come join  party Plus...  10     93.26  97.69   \n",
      "8  36  Trump appears  encourage  owners  take action ...  10     93.26  97.69   \n",
      "9  39  Obama  Trump winning Anything possible  #politics   6     62.04  50.00   \n",
      "\n",
      "   Authentic  Tone  WPS  Sixltr     Dic  ...  SemiC  QMark  Exclam  Dash  \\\n",
      "0       1.00  99.0    4   50.00  100.00  ...      0    0.0     0.0     0   \n",
      "1       4.97  99.0    9   55.56   22.22  ...      0    0.0     0.0     0   \n",
      "2       1.00  99.0    3  100.00   33.33  ...      0    0.0     0.0     0   \n",
      "3      17.46  99.0   13   53.85   53.85  ...      0    0.0     0.0     0   \n",
      "4       1.79  99.0   12   50.00   33.33  ...      0    0.0     0.0     0   \n",
      "5       1.00  99.0   12   58.33   41.67  ...      0    0.0     0.0     0   \n",
      "6       4.97  99.0    9   22.22   66.67  ...      0    0.0     0.0     0   \n",
      "7      43.37  99.0   10   40.00   60.00  ...      0    0.0     0.0     0   \n",
      "8       3.37  99.0   10   40.00   60.00  ...      0    0.0     0.0     0   \n",
      "9       1.00  99.0    6   66.67   66.67  ...      0    0.0     0.0     0   \n",
      "\n",
      "   Quote  Apostro  Parenth  OtherP  Troll  Positive  \n",
      "0    0.0      0.0        0   25.00      1         0  \n",
      "1    0.0      0.0        0    0.00      1         0  \n",
      "2    0.0      0.0        0    0.00      1         0  \n",
      "3    0.0      0.0        0   15.38      1         0  \n",
      "4    0.0      0.0        0   33.33      1         0  \n",
      "5    0.0      0.0        0   41.67      1         0  \n",
      "6    0.0      0.0        0   22.22      1         0  \n",
      "7    0.0      0.0        0   30.00      1         0  \n",
      "8    0.0      0.0        0    0.00      1         0  \n",
      "9    0.0      0.0        0   16.67      1         0  \n",
      "\n",
      "[10 rows x 97 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d = pd.read_csv(r\"LIWCPosLabel.csv\")\n",
    "print(d[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\")) \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
    "    text = text.lower()\n",
    "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
    "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "    text = [word for word in text if not word in stop_words]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "d['Processed_Reviews'] = d.B.apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.309035464250455"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.Processed_Reviews.apply(lambda x: len(x.split(\" \"))).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-54537b3e9c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Processed_Reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlist_tokenized_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Processed_Reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(d['Processed_Reviews'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(d['Processed_Reviews'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-fafd16deedd0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m6000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_on_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Processed_Reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mlist_tokenized_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Processed_Reviews'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Convolution1D\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "\n",
    "max_features = 6000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(d['Processed_Reviews'])\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(d['Processed_Reviews'])\n",
    "\n",
    "maxlen = 130\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "y = d['Positive']\n",
    "\n",
    "embed_size = 128\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, embed_size))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences = True)))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(20, activation=\"relu\"))\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "batch_size = 100\n",
    "epochs = 3\n",
    "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(r\"LIWCPosLabel.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270316 train examples\n",
      "67579 validation examples\n",
      "84474 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dataframe, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "  dataframe = dataframe.copy()\n",
    "  labels = dataframe.pop('Troll')\n",
    "  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "  if shuffle:\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "  ds = ds.batch(batch_size)\n",
    "  return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a feature column\n",
    "# and to transform a batch of data\n",
    "def demo(feature_column):\n",
    "  feature_layer = layers.DenseFeatures(feature_column)\n",
    "  print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['WC', 'Analytic', 'Clout', 'Authentic', 'Tone', 'WPS', 'Sixltr', 'Dic', 'SemiC']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 171s 32ms/step - loss: 0.3747 - acc: 0.8365 - val_loss: 0.3288 - val_acc: 0.8553\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.3308 - acc: 0.8555 - val_loss: 0.3039 - val_acc: 0.8704\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.3094 - acc: 0.8685 - val_loss: 0.3029 - val_acc: 0.8728\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.3021 - acc: 0.8722 - val_loss: 0.2934 - val_acc: 0.8754\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.2968 - acc: 0.8748 - val_loss: 0.2873 - val_acc: 0.8809\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.2939 - acc: 0.8768 - val_loss: 0.2854 - val_acc: 0.8802\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.2913 - acc: 0.8774 - val_loss: 0.2849 - val_acc: 0.8821\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.2898 - acc: 0.8782 - val_loss: 0.2832 - val_acc: 0.8816\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.2879 - acc: 0.8791 - val_loss: 0.2909 - val_acc: 0.8773\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.2865 - acc: 0.8801 - val_loss: 0.2824 - val_acc: 0.8821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a4c5d45f8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 51s 30ms/step - loss: 0.2861 - acc: 0.8785\n",
      "Accuracy 0.8785425\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just with tone: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Tone']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 235s 43ms/step - loss: 0.7021 - acc: 0.5051 - val_loss: 0.6998 - val_acc: 0.5049\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.6929 - acc: 0.5068 - val_loss: 0.6922 - val_acc: 0.5135\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6924 - acc: 0.5074 - val_loss: 0.6923 - val_acc: 0.5054\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 42s 8ms/step - loss: 0.6924 - acc: 0.5044 - val_loss: 0.6923 - val_acc: 0.5054\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6924 - acc: 0.5042 - val_loss: 0.6923 - val_acc: 0.5054\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6924 - acc: 0.5054 - val_loss: 0.6923 - val_acc: 0.5049\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 42s 8ms/step - loss: 0.6924 - acc: 0.5058 - val_loss: 0.6922 - val_acc: 0.5054\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6924 - acc: 0.5041 - val_loss: 0.6922 - val_acc: 0.5049\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.6924 - acc: 0.5042 - val_loss: 0.6923 - val_acc: 0.5049\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6924 - acc: 0.5047 - val_loss: 0.6922 - val_acc: 0.5054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a43cd3908>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 79s 47ms/step - loss: 0.6925 - acc: 0.5029\n",
      "Accuracy 0.5028648\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just with authenticity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Authentic']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 284s 53ms/step - loss: 0.6910 - acc: 0.5602 - val_loss: 0.6812 - val_acc: 0.5733\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 50s 9ms/step - loss: 0.6815 - acc: 0.5711 - val_loss: 0.6847 - val_acc: 0.5617\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6799 - acc: 0.5753 - val_loss: 0.6785 - val_acc: 0.5845\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6787 - acc: 0.5772 - val_loss: 0.6775 - val_acc: 0.5743\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 46s 9ms/step - loss: 0.6783 - acc: 0.5757 - val_loss: 0.6774 - val_acc: 0.5732\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.6780 - acc: 0.5755 - val_loss: 0.6768 - val_acc: 0.5732\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.6778 - acc: 0.5752 - val_loss: 0.6770 - val_acc: 0.5809\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 46s 9ms/step - loss: 0.6777 - acc: 0.5751 - val_loss: 0.6769 - val_acc: 0.5767\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 46s 9ms/step - loss: 0.6774 - acc: 0.5744 - val_loss: 0.6768 - val_acc: 0.5785\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.6764 - acc: 0.5755 - val_loss: 0.6757 - val_acc: 0.5784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b689b7e10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 119s 71ms/step - loss: 0.6762 - acc: 0.5774\n",
      "Accuracy 0.57744396\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words caputed by dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Dic']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 357s 66ms/step - loss: 0.6782 - acc: 0.5746 - val_loss: 0.6846 - val_acc: 0.5910\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6603 - acc: 0.5940 - val_loss: 0.6607 - val_acc: 0.5934\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6574 - acc: 0.5970 - val_loss: 0.6556 - val_acc: 0.6101\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 40s 7ms/step - loss: 0.6566 - acc: 0.5991 - val_loss: 0.6562 - val_acc: 0.6013\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 41s 8ms/step - loss: 0.6564 - acc: 0.5997 - val_loss: 0.6548 - val_acc: 0.6009\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 42s 8ms/step - loss: 0.6555 - acc: 0.6009 - val_loss: 0.6545 - val_acc: 0.6101\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 40s 7ms/step - loss: 0.6534 - acc: 0.6018 - val_loss: 0.6513 - val_acc: 0.6144\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 40s 7ms/step - loss: 0.6503 - acc: 0.6086 - val_loss: 0.6472 - val_acc: 0.6255\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 40s 7ms/step - loss: 0.6475 - acc: 0.6134 - val_loss: 0.6463 - val_acc: 0.6020\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 40s 7ms/step - loss: 0.6456 - acc: 0.6141 - val_loss: 0.6431 - val_acc: 0.6199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bdea7d9b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 123s 73ms/step - loss: 0.6449 - acc: 0.6191\n",
      "Accuracy 0.6191491\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just Clout\n",
    "\n",
    "*** \"Higher Clout score is marked by using more we-words and social words and fewer I-words, negations (e.g., no, not), and swear words.\" ***\n",
    "\n",
    "Weiai Xu and Congcong Zhang in Sentiment, richness, authority, and relevance modelof information sharing during social Crisesâ€”the case of #MH370 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Clout']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 260s 48ms/step - loss: 0.5846 - acc: 0.7075 - val_loss: 0.5485 - val_acc: 0.7291\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 50s 9ms/step - loss: 0.5451 - acc: 0.7390 - val_loss: 0.5403 - val_acc: 0.7486\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.5392 - acc: 0.7481 - val_loss: 0.5405 - val_acc: 0.7501\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5378 - acc: 0.7486 - val_loss: 0.5349 - val_acc: 0.7489\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5369 - acc: 0.7495 - val_loss: 0.5346 - val_acc: 0.7505\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5358 - acc: 0.7496 - val_loss: 0.5331 - val_acc: 0.7505\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5321 - acc: 0.7499 - val_loss: 0.5247 - val_acc: 0.7507\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5264 - acc: 0.7502 - val_loss: 0.5217 - val_acc: 0.7507\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.5222 - acc: 0.7546 - val_loss: 0.5206 - val_acc: 0.7534\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 51s 9ms/step - loss: 0.5202 - acc: 0.7578 - val_loss: 0.5301 - val_acc: 0.7649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d6e91fda0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 95s 56ms/step - loss: 0.5321 - acc: 0.7624\n",
      "Accuracy 0.76240027\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combination: Clout and Tone\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Clout', 'Tone']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 348s 64ms/step - loss: 0.5771 - acc: 0.7159 - val_loss: 0.5519 - val_acc: 0.7258\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.5472 - acc: 0.7383 - val_loss: 0.5369 - val_acc: 0.7479\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 46s 8ms/step - loss: 0.5369 - acc: 0.7472 - val_loss: 0.5330 - val_acc: 0.7579\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5270 - acc: 0.7512 - val_loss: 0.5316 - val_acc: 0.7531\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.5210 - acc: 0.7533 - val_loss: 0.5176 - val_acc: 0.7541\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.5181 - acc: 0.7556 - val_loss: 0.5200 - val_acc: 0.7555\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.5169 - acc: 0.7565 - val_loss: 0.5171 - val_acc: 0.7540\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.5154 - acc: 0.7580 - val_loss: 0.5260 - val_acc: 0.7601\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.5148 - acc: 0.7586 - val_loss: 0.5255 - val_acc: 0.7592\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.5146 - acc: 0.7583 - val_loss: 0.5123 - val_acc: 0.7628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e24860a90>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 122s 72ms/step - loss: 0.5152 - acc: 0.7614\n",
      "Accuracy 0.7614059\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combi Clout and Authenticity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Clout', 'Authentic']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 392s 72ms/step - loss: 0.5818 - acc: 0.7112 - val_loss: 0.5444 - val_acc: 0.7376\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.5465 - acc: 0.7333 - val_loss: 0.5380 - val_acc: 0.7430\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5354 - acc: 0.7398 - val_loss: 0.5275 - val_acc: 0.7443\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 46s 8ms/step - loss: 0.5320 - acc: 0.7429 - val_loss: 0.5282 - val_acc: 0.7439\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5296 - acc: 0.7450 - val_loss: 0.5276 - val_acc: 0.7432\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5252 - acc: 0.7500 - val_loss: 0.5198 - val_acc: 0.7552\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5212 - acc: 0.7556 - val_loss: 0.5201 - val_acc: 0.7549\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5180 - acc: 0.7586 - val_loss: 0.5138 - val_acc: 0.7673\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5156 - acc: 0.7601 - val_loss: 0.5118 - val_acc: 0.7658\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5136 - acc: 0.7609 - val_loss: 0.5241 - val_acc: 0.7597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e7b481e10>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 154s 91ms/step - loss: 0.5282 - acc: 0.7584\n",
      "Accuracy 0.75837535\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combi: Authentic, tone and clout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Clout', 'Authentic', \"Tone\"]:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 557s 103ms/step - loss: 0.5758 - acc: 0.7153 - val_loss: 0.5464 - val_acc: 0.7391\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 50s 9ms/step - loss: 0.5417 - acc: 0.7376 - val_loss: 0.5335 - val_acc: 0.7439\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5299 - acc: 0.7465 - val_loss: 0.5222 - val_acc: 0.7470\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.5200 - acc: 0.7542 - val_loss: 0.5109 - val_acc: 0.7583\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5149 - acc: 0.7573 - val_loss: 0.5133 - val_acc: 0.7519\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.5122 - acc: 0.7584 - val_loss: 0.5070 - val_acc: 0.7614\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.5098 - acc: 0.7590 - val_loss: 0.5084 - val_acc: 0.7579\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5086 - acc: 0.7596 - val_loss: 0.5095 - val_acc: 0.7554\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5084 - acc: 0.7595 - val_loss: 0.5052 - val_acc: 0.7608\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5061 - acc: 0.7612 - val_loss: 0.5051 - val_acc: 0.7623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d203811d0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 206s 122ms/step - loss: 0.5086 - acc: 0.7605\n",
      "Accuracy 0.7604707\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just analytic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Pia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/Pia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 71s 13ms/step - loss: 0.7107 - acc: 0.5079 - val_loss: 0.6923 - val_acc: 0.5253\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 51s 9ms/step - loss: 0.6933 - acc: 0.5164 - val_loss: 0.6908 - val_acc: 0.5311\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 50s 9ms/step - loss: 0.6915 - acc: 0.5205 - val_loss: 0.6904 - val_acc: 0.5366\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 52s 10ms/step - loss: 0.6908 - acc: 0.5253 - val_loss: 0.6898 - val_acc: 0.5311\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 51s 9ms/step - loss: 0.6903 - acc: 0.5259 - val_loss: 0.6897 - val_acc: 0.5379\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.6901 - acc: 0.5252 - val_loss: 0.6894 - val_acc: 0.5320\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.6899 - acc: 0.5260 - val_loss: 0.6893 - val_acc: 0.5308\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 42s 8ms/step - loss: 0.6898 - acc: 0.5261 - val_loss: 0.6896 - val_acc: 0.5488\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 57s 11ms/step - loss: 0.6898 - acc: 0.5269 - val_loss: 0.6894 - val_acc: 0.5297\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 75s 14ms/step - loss: 0.6897 - acc: 0.5274 - val_loss: 0.6893 - val_acc: 0.5301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a3b43a828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Analytic']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 18s 11ms/step - loss: 0.6904 - acc: 0.5258\n",
      "Accuracy 0.5258068\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just WPS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 468s 87ms/step - loss: 0.4551 - acc: 0.7551 - val_loss: 0.4354 - val_acc: 0.7726\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 52s 10ms/step - loss: 0.4334 - acc: 0.7682 - val_loss: 0.4350 - val_acc: 0.7659\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.4320 - acc: 0.7690 - val_loss: 0.4279 - val_acc: 0.7705\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.4314 - acc: 0.7691 - val_loss: 0.4287 - val_acc: 0.7726\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.4308 - acc: 0.7696 - val_loss: 0.4272 - val_acc: 0.7726\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.4308 - acc: 0.7690 - val_loss: 0.4271 - val_acc: 0.7726\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.4305 - acc: 0.7698 - val_loss: 0.4292 - val_acc: 0.7705\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.4307 - acc: 0.7692 - val_loss: 0.4278 - val_acc: 0.7726\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.4303 - acc: 0.7696 - val_loss: 0.4275 - val_acc: 0.7726\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.4302 - acc: 0.7695 - val_loss: 0.4287 - val_acc: 0.7705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d0c5f0860>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['WPS']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 191s 113ms/step - loss: 0.4323 - acc: 0.7663\n",
      "Accuracy 0.7662713\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just Sixltr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Pia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /Users/Pia/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 59s 11ms/step - loss: 0.5909 - acc: 0.6835 - val_loss: 0.5898 - val_acc: 0.6915\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 46s 9ms/step - loss: 0.5815 - acc: 0.6919 - val_loss: 0.5771 - val_acc: 0.6963\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 64s 12ms/step - loss: 0.5799 - acc: 0.6936 - val_loss: 0.5771 - val_acc: 0.6941\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 44s 8ms/step - loss: 0.5795 - acc: 0.6941 - val_loss: 0.5787 - val_acc: 0.6899\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 43s 8ms/step - loss: 0.5793 - acc: 0.6950 - val_loss: 0.5766 - val_acc: 0.6969\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 57s 11ms/step - loss: 0.5792 - acc: 0.6948 - val_loss: 0.5767 - val_acc: 0.6969\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 57s 11ms/step - loss: 0.5792 - acc: 0.6952 - val_loss: 0.5764 - val_acc: 0.6965\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 60s 11ms/step - loss: 0.5791 - acc: 0.6950 - val_loss: 0.5769 - val_acc: 0.6997\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.5789 - acc: 0.6953 - val_loss: 0.5770 - val_acc: 0.6997\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.5788 - acc: 0.6948 - val_loss: 0.5788 - val_acc: 0.6899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c41b1ad68>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['Sixltr']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 16s 9ms/step - loss: 0.5823 - acc: 0.6880\n",
      "Accuracy 0.6879632\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just SemiC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5407 steps, validate on 1352 steps\n",
      "Epoch 1/10\n",
      "5407/5407 [==============================] - 114s 21ms/step - loss: 0.6931 - acc: 0.5031 - val_loss: 0.6931 - val_acc: 0.5075\n",
      "Epoch 2/10\n",
      "5407/5407 [==============================] - 47s 9ms/step - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6930 - val_acc: 0.5075\n",
      "Epoch 3/10\n",
      "5407/5407 [==============================] - 49s 9ms/step - loss: 0.6931 - acc: 0.5037 - val_loss: 0.6930 - val_acc: 0.5075\n",
      "Epoch 4/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6931 - val_acc: 0.5075\n",
      "Epoch 5/10\n",
      "5407/5407 [==============================] - 51s 9ms/step - loss: 0.6931 - acc: 0.5034 - val_loss: 0.6930 - val_acc: 0.5075\n",
      "Epoch 6/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6930 - val_acc: 0.5075\n",
      "Epoch 7/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.6931 - acc: 0.5037 - val_loss: 0.6930 - val_acc: 0.5075\n",
      "Epoch 8/10\n",
      "5407/5407 [==============================] - 45s 8ms/step - loss: 0.6931 - acc: 0.5045 - val_loss: 0.6930 - val_acc: 0.5075\n",
      "Epoch 9/10\n",
      "5407/5407 [==============================] - 48s 9ms/step - loss: 0.6931 - acc: 0.5029 - val_loss: 0.6930 - val_acc: 0.5075\n",
      "Epoch 10/10\n",
      "5407/5407 [==============================] - 46s 8ms/step - loss: 0.6931 - acc: 0.5033 - val_loss: 0.6930 - val_acc: 0.5075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c4b924d68>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_columns = []\n",
    "# numeric cols\n",
    "for header in ['SemiC']:\n",
    "  feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)\n",
    "\n",
    "batch_size = 50\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/1690 [==============================] - 36s 21ms/step - loss: 0.6931 - acc: 0.5051\n",
      "Accuracy 0.505114\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             Features  Accuracy\n",
      "0   WC Analytic Clout Authentic Tone WPS Sicltr Di...  0.878543\n",
      "1                                                Tone  0.502865\n",
      "2                                           Authentic  0.578400\n",
      "3                                                 Dic  0.619149\n",
      "4                                               Clout  0.762400\n",
      "5                                          Clout Tone  0.525807\n",
      "6                                     Clout Authentic  0.761406\n",
      "7                                Clout Authentic Tone  0.758375\n",
      "8                                            Analytic  0.525807\n",
      "9                                                 WPS  0.766271\n",
      "10                                             Sixltr  0.687963\n",
      "11                                              SemiC  0.505114\n"
     ]
    }
   ],
   "source": [
    "Data = {'Features':['WC Analytic Clout Authentic Tone WPS Sicltr Dic SemiC', 'Tone', 'Authentic', 'Dic', \"Clout\", \"Clout Tone\", \"Clout Authentic\", \"Clout Authentic Tone\", \"Analytic\", \"WPS\", \"Sixltr\", \"SemiC\"], 'Accuracy':[0.8785425, 0.5028648, 0.5784, 0.6191491, 0.76240027, 0.5258068, 0.7614059, 0.75837535, 0.5258068, 0.7662713, 0.6879632, 0.505114]} \n",
    "\n",
    "df = pd.DataFrame(Data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1c9ee2b240>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df.plot(x ='Features', y='Accuracy', kind = 'bar', color=['CadetBlue', 'LightSteelBlue', 'PowderBlue', 'SteelBlue'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
